{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40037bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0420c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "\n",
    "class BetaUNet(nn.Module):\n",
    "    \"\"\"A mixture of BetaVAE and UNet.\"\"\"\n",
    "    def __init__(self, beta=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dconv_down1 = conv(3, 64, kernel_size=3, stride=2)\n",
    "        self.dconv_down2 = conv(64, 128, kernel_size=3, stride=2)\n",
    "        self.dconv_down3 = conv(128, 256, kernel_size=3, stride=2)\n",
    "        self.dconv_down4 = conv(256, 512, kernel_size=3, stride=2)\n",
    "        self.dconv_down5 = conv(512, 512, kernel_size=6, padding=0)\n",
    "\n",
    "        self.mu_fc = nn.Linear(512, 256)\n",
    "        self.logvar_fc = nn.Linear(512, 256)  # isotropic Gaussian\n",
    "\n",
    "        self.latent_fc = nn.Linear(256, 512)\n",
    "\n",
    "        self.up5 = nn.ConvTranspose2d(512, 512, kernel_size=6)\n",
    "        self.dconv_up5 = conv(512+512, 512, kernel_size=3, stride=1)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(512, 512, kernel_size=2, stride=2)  \n",
    "        self.dconv_up4 = conv(512+256, 256, kernel_size=3, stride=1)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(256, 256, kernel_size=2, stride=2)\n",
    "        self.dconv_up3 = conv(256+128, 128, kernel_size=3, stride=1)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(128, 128, kernel_size=2, stride=2)\n",
    "        self.dconv_up2 = conv(128+64, 64, kernel_size=3, stride=1)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2)\n",
    "        self.conv_last = nn.Conv2d(64, 3, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        conv2 = self.dconv_down2(conv1)\n",
    "        conv3 = self.dconv_down3(conv2)\n",
    "        conv4 = self.dconv_down4(conv3)\n",
    "        conv5 = self.dconv_down5(conv4)\n",
    "        encoding = conv5.view(-1, 512)\n",
    "        \n",
    "        mu = self.mu_fc(encoding)\n",
    "        logvar = self.logvar_fc(encoding)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        latent_sample = std * torch.randn_like(logvar) + mu\n",
    "        latent_out = self.latent_fc(latent_sample)\n",
    "        latent_out = latent_out.view(-1, 512, 1, 1)\n",
    "        \n",
    "        conv5_up = self.up5(latent_out)\n",
    "        dconv_up5 = self.dconv_up5(torch.cat([conv5_up, conv4], dim=1))\n",
    "        conv4_up = self.up4(dconv_up5)\n",
    "        dconv_up4 = self.dconv_up4(torch.cat([conv4_up, conv3], dim=1))\n",
    "        conv3_up = self.up3(dconv_up4)\n",
    "        dconv_up3 = self.dconv_up3(torch.cat([conv3_up, conv2], dim=1))\n",
    "        conv2_up = self.up2(dconv_up3)\n",
    "        dconv_up2 = self.dconv_up2(torch.cat([conv2_up, conv1], dim=1))\n",
    "        conv1_up = self.up1(dconv_up2)\n",
    "        out = self.conv_last(conv1_up)\n",
    "        \n",
    "        return torch.sigmoid(out), mu, std**2\n",
    "    \n",
    "    def loss(self, prediction, original, mu, var):\n",
    "        reconstruction_loss = F.binary_cross_entropy(\n",
    "            prediction, original, reduction=\"sum\"\n",
    "        )\n",
    "\n",
    "        kl_divergence = -0.5 * (1 + var.log() - mu**2 - var).sum()\n",
    "        \n",
    "        return reconstruction_loss + self.beta * kl_divergence\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class=3):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = conv(3, 64, kernel_size=3, stride=2)\n",
    "        self.dconv_down2 = conv(64, 128, kernel_size=3, stride=2)\n",
    "        self.dconv_down3 = conv(128, 256, kernel_size=3, stride=2)\n",
    "        self.dconv_down4 = conv(256, 512, kernel_size=3, stride=2)        \n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(512, 512, kernel_size=2, stride=2)  \n",
    "        self.dconv_up4 = conv(512+256, 256, kernel_size=3, stride=1) \n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(256, 256, kernel_size=2, stride=2)  \n",
    "        self.dconv_up3 = conv(256+128, 128, kernel_size=3, stride=1) \n",
    "\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(128, 128, kernel_size=2, stride=2)  \n",
    "        self.dconv_up2 = conv(128+64, 64, kernel_size=3, stride=1) \n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2)  \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        conv1 = self.dconv_down1(x)\n",
    "        conv2 = self.dconv_down2(conv1)\n",
    "        conv3 = self.dconv_down3(conv2)\n",
    "        conv4 = self.dconv_down4(conv3)\n",
    "        \n",
    "       \n",
    "        conv4_up = self.up4(conv4)\n",
    "        dconv_up4 = self.dconv_up4(torch.cat([conv4_up, conv3], dim=1))\n",
    "        conv3_up = self.up3(dconv_up4)\n",
    "        dconv_up3 = self.dconv_up3(torch.cat([conv3_up, conv2], dim=1))\n",
    "        conv2_up = self.up2(dconv_up3)\n",
    "        dconv_up2 = self.dconv_up2(torch.cat([conv2_up, conv1], dim=1))\n",
    "        conv1_up = self.up1(dconv_up2)\n",
    "\n",
    "        out = self.conv_last(conv1_up)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SimpleAutoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 128)\n",
    "        self.fc2 = nn.Linear(128, 64 * 12 * 12)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(64, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        out = out.view(-1, 64 * 12 * 12 )\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = out.view(-1, 64,12,12)\n",
    "        out = self.decoder(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4912518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 64, 48, 48]          --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 48, 48]          1,792\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 64, 48, 48]          128\n",
      "|    └─ReLU: 2-3                         [-1, 64, 48, 48]          --\n",
      "├─Sequential: 1-2                        [-1, 128, 24, 24]         --\n",
      "|    └─Conv2d: 2-4                       [-1, 128, 24, 24]         73,856\n",
      "|    └─BatchNorm2d: 2-5                  [-1, 128, 24, 24]         256\n",
      "|    └─ReLU: 2-6                         [-1, 128, 24, 24]         --\n",
      "├─Sequential: 1-3                        [-1, 256, 12, 12]         --\n",
      "|    └─Conv2d: 2-7                       [-1, 256, 12, 12]         295,168\n",
      "|    └─BatchNorm2d: 2-8                  [-1, 256, 12, 12]         512\n",
      "|    └─ReLU: 2-9                         [-1, 256, 12, 12]         --\n",
      "├─Sequential: 1-4                        [-1, 512, 6, 6]           --\n",
      "|    └─Conv2d: 2-10                      [-1, 512, 6, 6]           1,180,160\n",
      "|    └─BatchNorm2d: 2-11                 [-1, 512, 6, 6]           1,024\n",
      "|    └─ReLU: 2-12                        [-1, 512, 6, 6]           --\n",
      "├─ConvTranspose2d: 1-5                   [-1, 512, 12, 12]         1,049,088\n",
      "├─Sequential: 1-6                        [-1, 256, 12, 12]         --\n",
      "|    └─Conv2d: 2-13                      [-1, 256, 12, 12]         1,769,728\n",
      "|    └─BatchNorm2d: 2-14                 [-1, 256, 12, 12]         512\n",
      "|    └─ReLU: 2-15                        [-1, 256, 12, 12]         --\n",
      "├─ConvTranspose2d: 1-7                   [-1, 256, 24, 24]         262,400\n",
      "├─Sequential: 1-8                        [-1, 128, 24, 24]         --\n",
      "|    └─Conv2d: 2-16                      [-1, 128, 24, 24]         442,496\n",
      "|    └─BatchNorm2d: 2-17                 [-1, 128, 24, 24]         256\n",
      "|    └─ReLU: 2-18                        [-1, 128, 24, 24]         --\n",
      "├─ConvTranspose2d: 1-9                   [-1, 128, 48, 48]         65,664\n",
      "├─Sequential: 1-10                       [-1, 64, 48, 48]          --\n",
      "|    └─Conv2d: 2-19                      [-1, 64, 48, 48]          110,656\n",
      "|    └─BatchNorm2d: 2-20                 [-1, 64, 48, 48]          128\n",
      "|    └─ReLU: 2-21                        [-1, 64, 48, 48]          --\n",
      "├─ConvTranspose2d: 1-11                  [-1, 64, 96, 96]          16,448\n",
      "├─Conv2d: 1-12                           [-1, 3, 96, 96]           195\n",
      "==========================================================================================\n",
      "Total params: 5,270,467\n",
      "Trainable params: 5,270,467\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 1.51\n",
      "==========================================================================================\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 16.80\n",
      "Params size (MB): 20.11\n",
      "Estimated Total Size (MB): 37.02\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 64, 48, 48]          --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 48, 48]          1,792\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 64, 48, 48]          128\n",
       "|    └─ReLU: 2-3                         [-1, 64, 48, 48]          --\n",
       "├─Sequential: 1-2                        [-1, 128, 24, 24]         --\n",
       "|    └─Conv2d: 2-4                       [-1, 128, 24, 24]         73,856\n",
       "|    └─BatchNorm2d: 2-5                  [-1, 128, 24, 24]         256\n",
       "|    └─ReLU: 2-6                         [-1, 128, 24, 24]         --\n",
       "├─Sequential: 1-3                        [-1, 256, 12, 12]         --\n",
       "|    └─Conv2d: 2-7                       [-1, 256, 12, 12]         295,168\n",
       "|    └─BatchNorm2d: 2-8                  [-1, 256, 12, 12]         512\n",
       "|    └─ReLU: 2-9                         [-1, 256, 12, 12]         --\n",
       "├─Sequential: 1-4                        [-1, 512, 6, 6]           --\n",
       "|    └─Conv2d: 2-10                      [-1, 512, 6, 6]           1,180,160\n",
       "|    └─BatchNorm2d: 2-11                 [-1, 512, 6, 6]           1,024\n",
       "|    └─ReLU: 2-12                        [-1, 512, 6, 6]           --\n",
       "├─ConvTranspose2d: 1-5                   [-1, 512, 12, 12]         1,049,088\n",
       "├─Sequential: 1-6                        [-1, 256, 12, 12]         --\n",
       "|    └─Conv2d: 2-13                      [-1, 256, 12, 12]         1,769,728\n",
       "|    └─BatchNorm2d: 2-14                 [-1, 256, 12, 12]         512\n",
       "|    └─ReLU: 2-15                        [-1, 256, 12, 12]         --\n",
       "├─ConvTranspose2d: 1-7                   [-1, 256, 24, 24]         262,400\n",
       "├─Sequential: 1-8                        [-1, 128, 24, 24]         --\n",
       "|    └─Conv2d: 2-16                      [-1, 128, 24, 24]         442,496\n",
       "|    └─BatchNorm2d: 2-17                 [-1, 128, 24, 24]         256\n",
       "|    └─ReLU: 2-18                        [-1, 128, 24, 24]         --\n",
       "├─ConvTranspose2d: 1-9                   [-1, 128, 48, 48]         65,664\n",
       "├─Sequential: 1-10                       [-1, 64, 48, 48]          --\n",
       "|    └─Conv2d: 2-19                      [-1, 64, 48, 48]          110,656\n",
       "|    └─BatchNorm2d: 2-20                 [-1, 64, 48, 48]          128\n",
       "|    └─ReLU: 2-21                        [-1, 64, 48, 48]          --\n",
       "├─ConvTranspose2d: 1-11                  [-1, 64, 96, 96]          16,448\n",
       "├─Conv2d: 1-12                           [-1, 3, 96, 96]           195\n",
       "==========================================================================================\n",
       "Total params: 5,270,467\n",
       "Trainable params: 5,270,467\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.51\n",
       "==========================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 16.80\n",
       "Params size (MB): 20.11\n",
       "Estimated Total Size (MB): 37.02\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNet(n_class=3)\n",
    "summary(model, (3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80193700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 64, 48, 48]          --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 48, 48]          1,792\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 64, 48, 48]          128\n",
      "|    └─ReLU: 2-3                         [-1, 64, 48, 48]          --\n",
      "├─Sequential: 1-2                        [-1, 128, 24, 24]         --\n",
      "|    └─Conv2d: 2-4                       [-1, 128, 24, 24]         73,856\n",
      "|    └─BatchNorm2d: 2-5                  [-1, 128, 24, 24]         256\n",
      "|    └─ReLU: 2-6                         [-1, 128, 24, 24]         --\n",
      "├─Sequential: 1-3                        [-1, 256, 12, 12]         --\n",
      "|    └─Conv2d: 2-7                       [-1, 256, 12, 12]         295,168\n",
      "|    └─BatchNorm2d: 2-8                  [-1, 256, 12, 12]         512\n",
      "|    └─ReLU: 2-9                         [-1, 256, 12, 12]         --\n",
      "├─Sequential: 1-4                        [-1, 512, 6, 6]           --\n",
      "|    └─Conv2d: 2-10                      [-1, 512, 6, 6]           1,180,160\n",
      "|    └─BatchNorm2d: 2-11                 [-1, 512, 6, 6]           1,024\n",
      "|    └─ReLU: 2-12                        [-1, 512, 6, 6]           --\n",
      "├─Sequential: 1-5                        [-1, 512, 1, 1]           --\n",
      "|    └─Conv2d: 2-13                      [-1, 512, 1, 1]           9,437,696\n",
      "|    └─BatchNorm2d: 2-14                 [-1, 512, 1, 1]           1,024\n",
      "|    └─ReLU: 2-15                        [-1, 512, 1, 1]           --\n",
      "├─Linear: 1-6                            [-1, 256]                 131,328\n",
      "├─Linear: 1-7                            [-1, 256]                 131,328\n",
      "├─Linear: 1-8                            [-1, 512]                 131,584\n",
      "├─ConvTranspose2d: 1-9                   [-1, 512, 6, 6]           9,437,696\n",
      "├─Sequential: 1-10                       [-1, 512, 6, 6]           --\n",
      "|    └─Conv2d: 2-16                      [-1, 512, 6, 6]           4,719,104\n",
      "|    └─BatchNorm2d: 2-17                 [-1, 512, 6, 6]           1,024\n",
      "|    └─ReLU: 2-18                        [-1, 512, 6, 6]           --\n",
      "├─ConvTranspose2d: 1-11                  [-1, 512, 12, 12]         1,049,088\n",
      "├─Sequential: 1-12                       [-1, 256, 12, 12]         --\n",
      "|    └─Conv2d: 2-19                      [-1, 256, 12, 12]         1,769,728\n",
      "|    └─BatchNorm2d: 2-20                 [-1, 256, 12, 12]         512\n",
      "|    └─ReLU: 2-21                        [-1, 256, 12, 12]         --\n",
      "├─ConvTranspose2d: 1-13                  [-1, 256, 24, 24]         262,400\n",
      "├─Sequential: 1-14                       [-1, 128, 24, 24]         --\n",
      "|    └─Conv2d: 2-22                      [-1, 128, 24, 24]         442,496\n",
      "|    └─BatchNorm2d: 2-23                 [-1, 128, 24, 24]         256\n",
      "|    └─ReLU: 2-24                        [-1, 128, 24, 24]         --\n",
      "├─ConvTranspose2d: 1-15                  [-1, 128, 48, 48]         65,664\n",
      "├─Sequential: 1-16                       [-1, 64, 48, 48]          --\n",
      "|    └─Conv2d: 2-25                      [-1, 64, 48, 48]          110,656\n",
      "|    └─BatchNorm2d: 2-26                 [-1, 64, 48, 48]          128\n",
      "|    └─ReLU: 2-27                        [-1, 64, 48, 48]          --\n",
      "├─ConvTranspose2d: 1-17                  [-1, 64, 96, 96]          16,448\n",
      "├─Conv2d: 1-18                           [-1, 3, 96, 96]           195\n",
      "==========================================================================================\n",
      "Total params: 29,261,251\n",
      "Trainable params: 29,261,251\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 2.04\n",
      "==========================================================================================\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 17.24\n",
      "Params size (MB): 111.62\n",
      "Estimated Total Size (MB): 128.97\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 64, 48, 48]          --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 48, 48]          1,792\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 64, 48, 48]          128\n",
       "|    └─ReLU: 2-3                         [-1, 64, 48, 48]          --\n",
       "├─Sequential: 1-2                        [-1, 128, 24, 24]         --\n",
       "|    └─Conv2d: 2-4                       [-1, 128, 24, 24]         73,856\n",
       "|    └─BatchNorm2d: 2-5                  [-1, 128, 24, 24]         256\n",
       "|    └─ReLU: 2-6                         [-1, 128, 24, 24]         --\n",
       "├─Sequential: 1-3                        [-1, 256, 12, 12]         --\n",
       "|    └─Conv2d: 2-7                       [-1, 256, 12, 12]         295,168\n",
       "|    └─BatchNorm2d: 2-8                  [-1, 256, 12, 12]         512\n",
       "|    └─ReLU: 2-9                         [-1, 256, 12, 12]         --\n",
       "├─Sequential: 1-4                        [-1, 512, 6, 6]           --\n",
       "|    └─Conv2d: 2-10                      [-1, 512, 6, 6]           1,180,160\n",
       "|    └─BatchNorm2d: 2-11                 [-1, 512, 6, 6]           1,024\n",
       "|    └─ReLU: 2-12                        [-1, 512, 6, 6]           --\n",
       "├─Sequential: 1-5                        [-1, 512, 1, 1]           --\n",
       "|    └─Conv2d: 2-13                      [-1, 512, 1, 1]           9,437,696\n",
       "|    └─BatchNorm2d: 2-14                 [-1, 512, 1, 1]           1,024\n",
       "|    └─ReLU: 2-15                        [-1, 512, 1, 1]           --\n",
       "├─Linear: 1-6                            [-1, 256]                 131,328\n",
       "├─Linear: 1-7                            [-1, 256]                 131,328\n",
       "├─Linear: 1-8                            [-1, 512]                 131,584\n",
       "├─ConvTranspose2d: 1-9                   [-1, 512, 6, 6]           9,437,696\n",
       "├─Sequential: 1-10                       [-1, 512, 6, 6]           --\n",
       "|    └─Conv2d: 2-16                      [-1, 512, 6, 6]           4,719,104\n",
       "|    └─BatchNorm2d: 2-17                 [-1, 512, 6, 6]           1,024\n",
       "|    └─ReLU: 2-18                        [-1, 512, 6, 6]           --\n",
       "├─ConvTranspose2d: 1-11                  [-1, 512, 12, 12]         1,049,088\n",
       "├─Sequential: 1-12                       [-1, 256, 12, 12]         --\n",
       "|    └─Conv2d: 2-19                      [-1, 256, 12, 12]         1,769,728\n",
       "|    └─BatchNorm2d: 2-20                 [-1, 256, 12, 12]         512\n",
       "|    └─ReLU: 2-21                        [-1, 256, 12, 12]         --\n",
       "├─ConvTranspose2d: 1-13                  [-1, 256, 24, 24]         262,400\n",
       "├─Sequential: 1-14                       [-1, 128, 24, 24]         --\n",
       "|    └─Conv2d: 2-22                      [-1, 128, 24, 24]         442,496\n",
       "|    └─BatchNorm2d: 2-23                 [-1, 128, 24, 24]         256\n",
       "|    └─ReLU: 2-24                        [-1, 128, 24, 24]         --\n",
       "├─ConvTranspose2d: 1-15                  [-1, 128, 48, 48]         65,664\n",
       "├─Sequential: 1-16                       [-1, 64, 48, 48]          --\n",
       "|    └─Conv2d: 2-25                      [-1, 64, 48, 48]          110,656\n",
       "|    └─BatchNorm2d: 2-26                 [-1, 64, 48, 48]          128\n",
       "|    └─ReLU: 2-27                        [-1, 64, 48, 48]          --\n",
       "├─ConvTranspose2d: 1-17                  [-1, 64, 96, 96]          16,448\n",
       "├─Conv2d: 1-18                           [-1, 3, 96, 96]           195\n",
       "==========================================================================================\n",
       "Total params: 29,261,251\n",
       "Trainable params: 29,261,251\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.04\n",
       "==========================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 17.24\n",
       "Params size (MB): 111.62\n",
       "Estimated Total Size (MB): 128.97\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BetaUNet()\n",
    "summary(model, (3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a781d588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63530b8f-f25f-403c-b703-03fcbc484404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ad57050c77180dc9ed5ccc7774a474d285089782a3b5193155c6c81d567ba30"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
