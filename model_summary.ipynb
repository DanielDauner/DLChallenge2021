{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40037bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0420c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "\n",
    "class BetaUNet(nn.Module):\n",
    "    \"\"\"A mixture of BetaVAE and UNet.\"\"\"\n",
    "    def __init__(self, beta=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dconv_down1 = conv(3, 64, kernel_size=3, stride=2)\n",
    "        self.dconv_down2 = conv(64, 128, kernel_size=3, stride=2)\n",
    "        self.dconv_down3 = conv(128, 256, kernel_size=3, stride=2)\n",
    "        self.dconv_down4 = conv(256, 512, kernel_size=3, stride=2)\n",
    "        self.dconv_down5 = conv(512, 512, kernel_size=6, padding=0)\n",
    "\n",
    "        self.mu_fc = nn.Linear(512, 256)\n",
    "        self.logvar_fc = nn.Linear(512, 256)  # isotropic Gaussian\n",
    "\n",
    "        self.latent_fc = nn.Linear(256, 512)\n",
    "\n",
    "        self.up5 = nn.ConvTranspose2d(512, 512, kernel_size=6)\n",
    "        self.dconv_up5 = conv(512+512, 512, kernel_size=3, stride=1)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(512, 512, kernel_size=2, stride=2)  \n",
    "        self.dconv_up4 = conv(512+256, 256, kernel_size=3, stride=1)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(256, 256, kernel_size=2, stride=2)\n",
    "        self.dconv_up3 = conv(256+128, 128, kernel_size=3, stride=1)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(128, 128, kernel_size=2, stride=2)\n",
    "        self.dconv_up2 = conv(128+64, 64, kernel_size=3, stride=1)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2)\n",
    "        self.conv_last = nn.Conv2d(64, 3, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        conv2 = self.dconv_down2(conv1)\n",
    "        conv3 = self.dconv_down3(conv2)\n",
    "        conv4 = self.dconv_down4(conv3)\n",
    "        conv5 = self.dconv_down5(conv4)\n",
    "        encoding = conv5.view(-1, 512)\n",
    "        \n",
    "        mu = self.mu_fc(encoding)\n",
    "        logvar = self.logvar_fc(encoding)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        latent_sample = std * torch.randn_like(logvar) + mu\n",
    "        latent_out = self.latent_fc(latent_sample)\n",
    "        latent_out = latent_out.view(-1, 512, 1, 1)\n",
    "        \n",
    "        conv5_up = self.up5(latent_out)\n",
    "        dconv_up5 = self.dconv_up5(torch.cat([conv5_up, conv4], dim=1))\n",
    "        conv4_up = self.up4(dconv_up5)\n",
    "        dconv_up4 = self.dconv_up4(torch.cat([conv4_up, conv3], dim=1))\n",
    "        conv3_up = self.up3(dconv_up4)\n",
    "        dconv_up3 = self.dconv_up3(torch.cat([conv3_up, conv2], dim=1))\n",
    "        conv2_up = self.up2(dconv_up3)\n",
    "        dconv_up2 = self.dconv_up2(torch.cat([conv2_up, conv1], dim=1))\n",
    "        conv1_up = self.up1(dconv_up2)\n",
    "        out = self.conv_last(conv1_up)\n",
    "        \n",
    "        return torch.sigmoid(out), mu, std**2\n",
    "    \n",
    "    def loss(self, prediction, original, mu, var):\n",
    "        reconstruction_loss = F.binary_cross_entropy(\n",
    "            prediction, original, reduction=\"sum\"\n",
    "        )\n",
    "\n",
    "        kl_divergence = -0.5 * (1 + var.log() - mu**2 - var).sum()\n",
    "        \n",
    "        return reconstruction_loss + self.beta * kl_divergence\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class=3):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = conv(3, 64, kernel_size=3, stride=2)\n",
    "        self.dconv_down2 = conv(64, 128, kernel_size=3, stride=2)\n",
    "        self.dconv_down3 = conv(128, 256, kernel_size=3, stride=2)\n",
    "        self.dconv_down4 = conv(256, 512, kernel_size=3, stride=2)        \n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(512, 512, kernel_size=2, stride=2)  \n",
    "        self.dconv_up4 = conv(512+256, 256, kernel_size=3, stride=1) \n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(256, 256, kernel_size=2, stride=2)  \n",
    "        self.dconv_up3 = conv(256+128, 128, kernel_size=3, stride=1) \n",
    "\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(128, 128, kernel_size=2, stride=2)  \n",
    "        self.dconv_up2 = conv(128+64, 64, kernel_size=3, stride=1) \n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2)  \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        conv1 = self.dconv_down1(x)\n",
    "        conv2 = self.dconv_down2(conv1)\n",
    "        conv3 = self.dconv_down3(conv2)\n",
    "        conv4 = self.dconv_down4(conv3)\n",
    "        \n",
    "       \n",
    "        conv4_up = self.up4(conv4)\n",
    "        dconv_up4 = self.dconv_up4(torch.cat([conv4_up, conv3], dim=1))\n",
    "        conv3_up = self.up3(dconv_up4)\n",
    "        dconv_up3 = self.dconv_up3(torch.cat([conv3_up, conv2], dim=1))\n",
    "        conv2_up = self.up2(dconv_up3)\n",
    "        dconv_up2 = self.dconv_up2(torch.cat([conv2_up, conv1], dim=1))\n",
    "        conv1_up = self.up1(dconv_up2)\n",
    "\n",
    "        out = self.conv_last(conv1_up)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SimpleAutoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 128)\n",
    "        self.fc2 = nn.Linear(128, 64 * 12 * 12)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(64, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        out = out.view(-1, 64 * 12 * 12 )\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = out.view(-1, 64,12,12)\n",
    "        out = self.decoder(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4912518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 48, 48]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 48, 48]             128\n",
      "              ReLU-3           [-1, 64, 48, 48]               0\n",
      "            Conv2d-4          [-1, 128, 24, 24]          73,856\n",
      "       BatchNorm2d-5          [-1, 128, 24, 24]             256\n",
      "              ReLU-6          [-1, 128, 24, 24]               0\n",
      "            Conv2d-7          [-1, 256, 12, 12]         295,168\n",
      "       BatchNorm2d-8          [-1, 256, 12, 12]             512\n",
      "              ReLU-9          [-1, 256, 12, 12]               0\n",
      "           Conv2d-10            [-1, 512, 6, 6]       1,180,160\n",
      "      BatchNorm2d-11            [-1, 512, 6, 6]           1,024\n",
      "             ReLU-12            [-1, 512, 6, 6]               0\n",
      "  ConvTranspose2d-13          [-1, 512, 12, 12]       1,049,088\n",
      "           Conv2d-14          [-1, 256, 12, 12]       1,769,728\n",
      "      BatchNorm2d-15          [-1, 256, 12, 12]             512\n",
      "             ReLU-16          [-1, 256, 12, 12]               0\n",
      "  ConvTranspose2d-17          [-1, 256, 24, 24]         262,400\n",
      "           Conv2d-18          [-1, 128, 24, 24]         442,496\n",
      "      BatchNorm2d-19          [-1, 128, 24, 24]             256\n",
      "             ReLU-20          [-1, 128, 24, 24]               0\n",
      "  ConvTranspose2d-21          [-1, 128, 48, 48]          65,664\n",
      "           Conv2d-22           [-1, 64, 48, 48]         110,656\n",
      "      BatchNorm2d-23           [-1, 64, 48, 48]             128\n",
      "             ReLU-24           [-1, 64, 48, 48]               0\n",
      "  ConvTranspose2d-25           [-1, 64, 96, 96]          16,448\n",
      "           Conv2d-26            [-1, 3, 96, 96]             195\n",
      "================================================================\n",
      "Total params: 5,270,467\n",
      "Trainable params: 5,270,467\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 20.88\n",
      "Params size (MB): 20.11\n",
      "Estimated Total Size (MB): 41.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = UNet(n_class=3)\n",
    "summary(model, (3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80193700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 48, 48]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 48, 48]             128\n",
      "              ReLU-3           [-1, 64, 48, 48]               0\n",
      "            Conv2d-4          [-1, 128, 24, 24]          73,856\n",
      "       BatchNorm2d-5          [-1, 128, 24, 24]             256\n",
      "              ReLU-6          [-1, 128, 24, 24]               0\n",
      "            Conv2d-7          [-1, 256, 12, 12]         295,168\n",
      "       BatchNorm2d-8          [-1, 256, 12, 12]             512\n",
      "              ReLU-9          [-1, 256, 12, 12]               0\n",
      "           Conv2d-10            [-1, 512, 6, 6]       1,180,160\n",
      "      BatchNorm2d-11            [-1, 512, 6, 6]           1,024\n",
      "             ReLU-12            [-1, 512, 6, 6]               0\n",
      "           Conv2d-13            [-1, 512, 1, 1]       9,437,696\n",
      "      BatchNorm2d-14            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-15            [-1, 512, 1, 1]               0\n",
      "           Linear-16                  [-1, 256]         131,328\n",
      "           Linear-17                  [-1, 256]         131,328\n",
      "           Linear-18                  [-1, 512]         131,584\n",
      "  ConvTranspose2d-19            [-1, 512, 6, 6]       9,437,696\n",
      "           Conv2d-20            [-1, 512, 6, 6]       4,719,104\n",
      "      BatchNorm2d-21            [-1, 512, 6, 6]           1,024\n",
      "             ReLU-22            [-1, 512, 6, 6]               0\n",
      "  ConvTranspose2d-23          [-1, 512, 12, 12]       1,049,088\n",
      "           Conv2d-24          [-1, 256, 12, 12]       1,769,728\n",
      "      BatchNorm2d-25          [-1, 256, 12, 12]             512\n",
      "             ReLU-26          [-1, 256, 12, 12]               0\n",
      "  ConvTranspose2d-27          [-1, 256, 24, 24]         262,400\n",
      "           Conv2d-28          [-1, 128, 24, 24]         442,496\n",
      "      BatchNorm2d-29          [-1, 128, 24, 24]             256\n",
      "             ReLU-30          [-1, 128, 24, 24]               0\n",
      "  ConvTranspose2d-31          [-1, 128, 48, 48]          65,664\n",
      "           Conv2d-32           [-1, 64, 48, 48]         110,656\n",
      "      BatchNorm2d-33           [-1, 64, 48, 48]             128\n",
      "             ReLU-34           [-1, 64, 48, 48]               0\n",
      "  ConvTranspose2d-35           [-1, 64, 96, 96]          16,448\n",
      "           Conv2d-36            [-1, 3, 96, 96]             195\n",
      "================================================================\n",
      "Total params: 29,261,251\n",
      "Trainable params: 29,261,251\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 21.46\n",
      "Params size (MB): 111.62\n",
      "Estimated Total Size (MB): 133.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = BetaUNet()\n",
    "summary(model, (3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a781d588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63530b8f-f25f-403c-b703-03fcbc484404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ad57050c77180dc9ed5ccc7774a474d285089782a3b5193155c6c81d567ba30"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
