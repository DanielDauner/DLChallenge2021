{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40037bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0420c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "\n",
    "class BetaUNet(nn.Module):\n",
    "    \"\"\"A mixture of BetaVAE and UNet.\"\"\"\n",
    "    def __init__(self, beta=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_dim = 2048\n",
    "\n",
    "        self.dconv_down1 = conv(3, 32, kernel_size=5, stride=2, padding=2)\n",
    "        self.dconv_down2 = conv(32, 64, kernel_size=5, stride=2, padding=2)\n",
    "        self.dconv_down3 = conv(64, 128, kernel_size=5, stride=2, padding=2)\n",
    "        self.dconv_down4 = conv(128, 256, kernel_size=5, stride=2, padding=2)\n",
    "        self.dconv_down5 = conv(256, 512, kernel_size=5, stride=1, padding=0)\n",
    "\n",
    "        self.mu_fc = nn.Linear(512 * 2 * 2, self.latent_dim)\n",
    "        self.logvar_fc = nn.Linear(512 * 2 * 2, self.latent_dim)  # isotropic Gaussian\n",
    "\n",
    "        self.latent_fc = nn.Linear(self.latent_dim, 512 * 2 * 2)\n",
    "\n",
    "        self.up5 = nn.ConvTranspose2d(512, 256, kernel_size=5)\n",
    "        self.dconv_up5 = conv(256 + 256, 256, kernel_size=3, stride=1)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)  \n",
    "        self.dconv_up4 = conv(128 + 128, 128, kernel_size=3, stride=1)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dconv_up3 = conv(64 + 64, 64, kernel_size=3, stride=1)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.dconv_up2 = conv(32 + 32, 32, kernel_size=3, stride=1)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(32, 32, kernel_size=2, stride=2)\n",
    "        self.conv_last = nn.Conv2d(32, 3, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        conv2 = self.dconv_down2(conv1)\n",
    "        conv3 = self.dconv_down3(conv2)\n",
    "        conv4 = self.dconv_down4(conv3)\n",
    "        conv5 = self.dconv_down5(conv4)\n",
    "        encoding = conv5.view(x.shape[0], -1)\n",
    "        \n",
    "        \n",
    "        mu = self.mu_fc(encoding)\n",
    "        logvar = self.logvar_fc(encoding)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        latent_sample = std * torch.randn_like(logvar) + mu\n",
    "        latent_out = self.latent_fc(latent_sample)\n",
    "        latent_out = latent_out.view(-1, 512, 2, 2)\n",
    "        \n",
    "        conv5_up = self.up5(latent_out)\n",
    "        dconv_up5 = self.dconv_up5(torch.cat([conv5_up, conv4], dim=1))\n",
    "        conv4_up = self.up4(dconv_up5)\n",
    "        dconv_up4 = self.dconv_up4(torch.cat([conv4_up, conv3], dim=1))\n",
    "        conv3_up = self.up3(dconv_up4)\n",
    "        dconv_up3 = self.dconv_up3(torch.cat([conv3_up, conv2], dim=1))\n",
    "        conv2_up = self.up2(dconv_up3)\n",
    "        dconv_up2 = self.dconv_up2(torch.cat([conv2_up, conv1], dim=1))\n",
    "        conv1_up = self.up1(dconv_up2)\n",
    "        out = self.conv_last(conv1_up)\n",
    "        \n",
    "        return torch.sigmoid(out), mu, std**2\n",
    "        # return conv5\n",
    "    \n",
    "    def loss(self, prediction, original, mu, var):\n",
    "        reconstruction_loss = F.binary_cross_entropy(\n",
    "            prediction, original, reduction=\"sum\"\n",
    "        )\n",
    "\n",
    "        kl_divergence = -0.5 * (1 + var.log() - mu**2 - var).sum()\n",
    "        \n",
    "        return reconstruction_loss + self.beta * kl_divergence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4912518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 48, 48]           2,432\n",
      "       BatchNorm2d-2           [-1, 32, 48, 48]              64\n",
      "              ReLU-3           [-1, 32, 48, 48]               0\n",
      "            Conv2d-4           [-1, 64, 24, 24]          51,264\n",
      "       BatchNorm2d-5           [-1, 64, 24, 24]             128\n",
      "              ReLU-6           [-1, 64, 24, 24]               0\n",
      "            Conv2d-7          [-1, 128, 12, 12]         204,928\n",
      "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
      "              ReLU-9          [-1, 128, 12, 12]               0\n",
      "           Conv2d-10            [-1, 256, 6, 6]         819,456\n",
      "      BatchNorm2d-11            [-1, 256, 6, 6]             512\n",
      "             ReLU-12            [-1, 256, 6, 6]               0\n",
      "           Conv2d-13            [-1, 512, 2, 2]       3,277,312\n",
      "      BatchNorm2d-14            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-15            [-1, 512, 2, 2]               0\n",
      "           Linear-16                 [-1, 2048]       4,196,352\n",
      "           Linear-17                 [-1, 2048]       4,196,352\n",
      "           Linear-18                 [-1, 2048]       4,196,352\n",
      "  ConvTranspose2d-19            [-1, 256, 6, 6]       3,277,056\n",
      "           Conv2d-20            [-1, 256, 6, 6]       1,179,904\n",
      "      BatchNorm2d-21            [-1, 256, 6, 6]             512\n",
      "             ReLU-22            [-1, 256, 6, 6]               0\n",
      "  ConvTranspose2d-23          [-1, 128, 12, 12]         131,200\n",
      "           Conv2d-24          [-1, 128, 12, 12]         295,040\n",
      "      BatchNorm2d-25          [-1, 128, 12, 12]             256\n",
      "             ReLU-26          [-1, 128, 12, 12]               0\n",
      "  ConvTranspose2d-27           [-1, 64, 24, 24]          32,832\n",
      "           Conv2d-28           [-1, 64, 24, 24]          73,792\n",
      "      BatchNorm2d-29           [-1, 64, 24, 24]             128\n",
      "             ReLU-30           [-1, 64, 24, 24]               0\n",
      "  ConvTranspose2d-31           [-1, 32, 48, 48]           8,224\n",
      "           Conv2d-32           [-1, 32, 48, 48]          18,464\n",
      "      BatchNorm2d-33           [-1, 32, 48, 48]              64\n",
      "             ReLU-34           [-1, 32, 48, 48]               0\n",
      "  ConvTranspose2d-35           [-1, 32, 96, 96]           4,128\n",
      "           Conv2d-36            [-1, 3, 96, 96]              99\n",
      "================================================================\n",
      "Total params: 21,968,131\n",
      "Trainable params: 21,968,131\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 9.94\n",
      "Params size (MB): 83.80\n",
      "Estimated Total Size (MB): 93.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = BetaUNet()\n",
    "summary(model, (3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63530b8f-f25f-403c-b703-03fcbc484404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "m = nn.Sigmoid()\n",
    "loss = nn.BCELoss()\n",
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.ones(input.shape)\n",
    "print(target)\n",
    "output = loss(m(input), target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bce53e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetaUNetLarge(nn.Module):\n",
    "    \"\"\"A mixture of BetaVAE and UNet.\"\"\"\n",
    "    def __init__(self, beta=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_dim = 2048\n",
    "\n",
    "        self.dconv_down1 = conv(3, 64, kernel_size=5, stride=2, padding=2)\n",
    "        self.dconv_down2 = conv(64, 128, kernel_size=5, stride=2, padding=2)\n",
    "        self.dconv_down3 = conv(128, 256, kernel_size=5, stride=2, padding=2)\n",
    "        self.dconv_down4 = conv(256, 512, kernel_size=5, stride=2, padding=2)\n",
    "        self.dconv_down5 = conv(512, 1024, kernel_size=5, stride=1, padding=0)\n",
    "\n",
    "        self.mu_fc = nn.Linear(1024 * 2 * 2, self.latent_dim)\n",
    "        self.logvar_fc = nn.Linear(1024 * 2 * 2, self.latent_dim)  # isotropic Gaussian\n",
    "\n",
    "        self.latent_fc = nn.Linear(self.latent_dim, 1024 * 2 * 2)\n",
    "\n",
    "        self.up5 = nn.ConvTranspose2d(1024, 512, kernel_size=5)\n",
    "        self.dconv_up5 = conv(512 + 512, 512, kernel_size=3, stride=1)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)  \n",
    "        self.dconv_up4 = conv(256 + 256, 256, kernel_size=3, stride=1)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dconv_up3 = conv(128 + 128, 128, kernel_size=3, stride=1)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dconv_up2 = conv(64 + 64, 64, kernel_size=3, stride=1)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2)\n",
    "        self.conv_last = nn.Conv2d(64, 3, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        conv2 = self.dconv_down2(conv1)\n",
    "        conv3 = self.dconv_down3(conv2)\n",
    "        conv4 = self.dconv_down4(conv3)\n",
    "        conv5 = self.dconv_down5(conv4)\n",
    "        encoding = conv5.view(x.shape[0], -1)\n",
    "        \n",
    "        mu = self.mu_fc(encoding)\n",
    "        logvar = self.logvar_fc(encoding)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        latent_sample = std * torch.randn_like(logvar) + mu\n",
    "        latent_out = self.latent_fc(latent_sample)\n",
    "        latent_out = latent_out.view(-1, 1024, 2, 2)\n",
    "        \n",
    "        conv5_up = self.up5(latent_out)\n",
    "        dconv_up5 = self.dconv_up5(torch.cat([conv5_up, conv4], dim=1))\n",
    "        conv4_up = self.up4(dconv_up5)\n",
    "        dconv_up4 = self.dconv_up4(torch.cat([conv4_up, conv3], dim=1))\n",
    "        conv3_up = self.up3(dconv_up4)\n",
    "        dconv_up3 = self.dconv_up3(torch.cat([conv3_up, conv2], dim=1))\n",
    "        conv2_up = self.up2(dconv_up3)\n",
    "        dconv_up2 = self.dconv_up2(torch.cat([conv2_up, conv1], dim=1))\n",
    "        conv1_up = self.up1(dconv_up2)\n",
    "        out = self.conv_last(conv1_up)\n",
    "        \n",
    "        return torch.sigmoid(out), mu, std**2\n",
    "        # return conv5\n",
    "    \n",
    "    def loss(self, prediction, original, mu, var):\n",
    "        reconstruction_loss = F.binary_cross_entropy(\n",
    "            prediction, original, reduction=\"sum\"\n",
    "        )\n",
    "\n",
    "        kl_divergence = -0.5 * (1 + var.log() - mu**2 - var).sum()\n",
    "        \n",
    "        return reconstruction_loss + self.beta * kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "213a8e15-a879-42db-a8fe-500b49f07101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 48, 48]           4,864\n",
      "       BatchNorm2d-2           [-1, 64, 48, 48]             128\n",
      "              ReLU-3           [-1, 64, 48, 48]               0\n",
      "            Conv2d-4          [-1, 128, 24, 24]         204,928\n",
      "       BatchNorm2d-5          [-1, 128, 24, 24]             256\n",
      "              ReLU-6          [-1, 128, 24, 24]               0\n",
      "            Conv2d-7          [-1, 256, 12, 12]         819,456\n",
      "       BatchNorm2d-8          [-1, 256, 12, 12]             512\n",
      "              ReLU-9          [-1, 256, 12, 12]               0\n",
      "           Conv2d-10            [-1, 512, 6, 6]       3,277,312\n",
      "      BatchNorm2d-11            [-1, 512, 6, 6]           1,024\n",
      "             ReLU-12            [-1, 512, 6, 6]               0\n",
      "           Conv2d-13           [-1, 1024, 2, 2]      13,108,224\n",
      "      BatchNorm2d-14           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-15           [-1, 1024, 2, 2]               0\n",
      "           Linear-16                 [-1, 2048]       8,390,656\n",
      "           Linear-17                 [-1, 2048]       8,390,656\n",
      "           Linear-18                 [-1, 4096]       8,392,704\n",
      "  ConvTranspose2d-19            [-1, 512, 6, 6]      13,107,712\n",
      "           Conv2d-20            [-1, 512, 6, 6]       4,719,104\n",
      "      BatchNorm2d-21            [-1, 512, 6, 6]           1,024\n",
      "             ReLU-22            [-1, 512, 6, 6]               0\n",
      "  ConvTranspose2d-23          [-1, 256, 12, 12]         524,544\n",
      "           Conv2d-24          [-1, 256, 12, 12]       1,179,904\n",
      "      BatchNorm2d-25          [-1, 256, 12, 12]             512\n",
      "             ReLU-26          [-1, 256, 12, 12]               0\n",
      "  ConvTranspose2d-27          [-1, 128, 24, 24]         131,200\n",
      "           Conv2d-28          [-1, 128, 24, 24]         295,040\n",
      "      BatchNorm2d-29          [-1, 128, 24, 24]             256\n",
      "             ReLU-30          [-1, 128, 24, 24]               0\n",
      "  ConvTranspose2d-31           [-1, 64, 48, 48]          32,832\n",
      "           Conv2d-32           [-1, 64, 48, 48]          73,792\n",
      "      BatchNorm2d-33           [-1, 64, 48, 48]             128\n",
      "             ReLU-34           [-1, 64, 48, 48]               0\n",
      "  ConvTranspose2d-35           [-1, 64, 96, 96]          16,448\n",
      "           Conv2d-36            [-1, 3, 96, 96]             195\n",
      "================================================================\n",
      "Total params: 62,675,459\n",
      "Trainable params: 62,675,459\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 19.63\n",
      "Params size (MB): 239.09\n",
      "Estimated Total Size (MB): 258.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = BetaUNetLarge()\n",
    "summary(model, (3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f9050-a6ed-4972-95b9-e9e13b348fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ad57050c77180dc9ed5ccc7774a474d285089782a3b5193155c6c81d567ba30"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
